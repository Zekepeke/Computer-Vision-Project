{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"jMdzf2Kfe4bQ"},"outputs":[],"source":["import torch.nn as nn\n","import torch\n","import numpy as np\n","from torch.utils.data import Dataset, DataLoader"]},{"cell_type":"markdown","metadata":{"id":"tnOOfJq0bO51"},"source":["### Classification classes number setting"]},{"cell_type":"markdown","source":[],"metadata":{"id":"3l0yMcUFsvUM"}},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1731989157119,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"},"user_tz":300},"id":"KdSBQ-YHZotl","outputId":"5268a54a-ee6a-4882-e646-51871a12005d"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["5"]},"metadata":{},"execution_count":43}],"source":["#datast_label = 'point_history_classifier_label.csv'\n","datast_label = 'landmark_points_labels.csv'\n","count = 0\n","with open(datast_label, 'r') as file:\n","  for line in file:\n","    count += 1\n","# Can change this later when updated labels\n","number_classes = count\n","number_classes"]},{"cell_type":"markdown","metadata":{"id":"XUWxclMPepfp"},"source":["### Choosing the device"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":675,"status":"ok","timestamp":1731989159272,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"},"user_tz":300},"id":"39L1SUeVepPv","outputId":"a431d090-460c-40e9-8173-1b76a937fa3e"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda')"]},"metadata":{},"execution_count":44}],"source":["device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n","device"]},{"cell_type":"markdown","metadata":{"id":"WrDwwarkbAaa"},"source":["### Each path to csv\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-rBeww74a7xR"},"outputs":[],"source":["# data = 'point_history.csv'\n","data_of_mediapipe = 'landmark_points.csv'"]},{"cell_type":"markdown","metadata":{"id":"f4-VRElBd-Q2"},"source":["### Reading the csv files and loading the learning data\n","\n","\n","https://www.w3schools.com/python/python_file_open.asp"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"166972V1p8K8wpygcyZxC8qd6CxjSyBCq"},"executionInfo":{"elapsed":5240,"status":"ok","timestamp":1731989167637,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"},"user_tz":300},"id":"rXzrnPVReBDm","outputId":"b7f3e8f1-0968-4b18-e27a-6ccf052474fb"},"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}],"source":["# Features for my model\n","X_data = []\n","# Labels for my model\n","y_data = []\n","def is_valid_float(value):\n","    try:\n","        float(value)\n","        return True\n","    except ValueError:\n","        return False\n","\n","with open(data_of_mediapipe, 'r') as file:\n","    for i, line in enumerate(file, start=1):\n","        values = line.strip().split(',')\n","        if not all(is_valid_float(v) for v in values[1:]):\n","            print(f\"Invalid features on line {i}: {line.strip()}\")\n","\n","with open(data_of_mediapipe, 'r') as file:\n","  for line in file:\n","    values = line.strip().split(',')\n","    label = int(values[0])  # First element as label\n","    features = [float(v) for v in values[1:]]  # Remaining as features\n","    X_data.append(features)\n","    y_data.append(label)\n","    print(f\"Label: {label}, Features: {features}\")"]},{"cell_type":"markdown","metadata":{"id":"pTWGip94RuLz"},"source":["### Convert lists to PyTorch tensors\n","\n","https://discuss.pytorch.org/t/best-way-to-convert-a-list-to-a-tensor/59949"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":200,"status":"ok","timestamp":1731989173256,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"},"user_tz":300},"id":"FwI4W0vORy2P","outputId":"819dc84c-7b0f-412d-9846-8743e172fad7"},"outputs":[{"output_type":"stream","name":"stdout","text":["input size:  42\n"]},{"output_type":"execute_result","data":{"text/plain":["tensor([0, 0, 0,  ..., 4, 4, 4])"]},"metadata":{},"execution_count":47}],"source":["# Finding the maximum number of features\n","max_features = len(X_data[0])\n","for feature in X_data:\n","  max_features = max(max_features, len(feature))\n","\n","print(\"input size: \", max_features)\n","\n","\n","# Pad shorter feature lists with zeros for consistent tensor shape\n","for features in X_data:\n","    features += [0.0] * (max_features - len(features))\n","\n","\n","\n","\n","X_tensor = torch.tensor(X_data, dtype=torch.float32)\n","y_tensor = torch.tensor(y_data, dtype=torch.long)\n","y_tensor"]},{"cell_type":"markdown","metadata":{"id":"o6BUc6gFbUjd"},"source":["### Feed forward model\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sEVTsksjFPqa"},"outputs":[],"source":["class Feedforward(nn.Module):\n","\n","    def __init__(self, input_size, num_classes):\n","\n","      super().__init__()\n","\n","      # nn.Sequential is a container that allows to build neural networks\n","      # in a sequential, layer-by-layer format.\n","      self.ff = nn.Sequential (\n","          # I'm guessing the number of inputs of labels?\n","          #\n","          # Have 4 labels for now Default, Moving Cursor, Scroll Down, Scroll Up\n","\n","          # CHANGED nn.Linear(input_size, 20) TO nn.Linear(input_size, 100) FOR NO MISMATCH\n","          nn.Linear(input_size, 100), # Input layer with the max length of the feature list, intermediate with 20 nodes\n","          nn.ReLU(), # Activation function\n","          nn.Linear(100, 100), # Intermediate layer with 100 nodes\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, 100),\n","          nn.ReLU(),\n","          nn.Linear(100, num_classes), # Output layer with `num_classes` nodes\n","          nn.Softmax(dim=1)  # Softmax for probabilities\n","      )\n","\n","    def forward(self, x):\n","        return self.ff(x)"]},{"cell_type":"markdown","metadata":{"id":"MxyqKSZ4Wzn1"},"source":["### Insatantiate the modelðŸ˜ˆ"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":206,"status":"ok","timestamp":1731989177848,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"},"user_tz":300},"id":"Ho97BCC4BZIE","colab":{"base_uri":"https://localhost:8080/"},"outputId":"24a30043-6b27-4032-dca5-4106cda1d1b2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Number of classes: 5\n","Max features: 42\n"]}],"source":["print(f\"Number of classes: {number_classes}\")\n","print(f\"Max features: {max_features}\")\n","\n","instantiated_model = Feedforward(input_size=max_features, num_classes=number_classes).to(device)"]},{"cell_type":"code","source":["class GestureDataset(Dataset):\n","    def __init__(self, data_file, transform=None):\n","        # train_loadertrain_loader\n","        # data_file (str): Path to the CSV file containing the data.\n","        # transform (callable, optional): A function/transform to apply to the features.\n","        self.data = []\n","        self.labels = []\n","        self.transform = transform\n","\n","        with open(data_file, 'r') as file:\n","            for line in file:\n","                # Split the line into components\n","                values = line.strip().split(',')\n","                label = int(values[0])  # The first value is the label\n","                features = list(map(float, values[1:]))  # Remaining values are features\n","                self.labels.append(label)\n","                self.data.append(features)\n","\n","        # Convert to tensors\n","        self.data = torch.tensor(self.data, dtype=torch.float32)\n","        self.labels = torch.tensor(self.labels, dtype=torch.long)\n","\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        # Return a single data sample and its label\n","        return self.data[idx], self.labels[idx]\n","\n","# Example usage\n","data_file = data_of_mediapipe\n","\n","# Optional normalization transform\n","def normalize(tensor):\n","    return (tensor - tensor.mean(dim=0)) / tensor.std(dim=0)\n","\n","# Create dataset instance\n","gesture_dataset = GestureDataset(data_file)\n","\n","# Wrap in DataLoader for batching\n","data_loader = DataLoader(gesture_dataset, batch_size=32, shuffle=True)\n","\n","# Test loading data\n","for features, labels in data_loader:\n","    print(\"Features batch shape:\", features.shape)\n","    print(\"Labels batch shape:\", labels.shape)\n","    break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CMX4Az3fDRq7","executionInfo":{"status":"ok","timestamp":1731989179448,"user_tz":300,"elapsed":391,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"}},"outputId":"170c922e-8b9a-400f-f33e-9ef8d50b5418"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Features batch shape: torch.Size([32, 42])\n","Labels batch shape: torch.Size([32])\n"]}]},{"cell_type":"code","source":["#Use the GPU if possible\n","instantiated_model.to(device)\n","# Data\n","training_data = gesture_dataset\n","\n","class WrappedDataLoader:\n","    def __init__(self, dl, func):\n","        self.dl = dl\n","        self.func = func\n","    def __len__(self):\n","        return len(self.dl)\n","    def __iter__(self):\n","        batches = iter(self.dl)\n","        for batch in batches:\n","            yield (self.func(*batch))\n","\n","#device defined in previous module\n","def toGPU(x, y):\n","    return x.to(device), y.to(device)\n","\n","train_loader = WrappedDataLoader(DataLoader(\n","    training_data, batch_size=100, shuffle=True, num_workers=1\n","), toGPU)\n"],"metadata":{"id":"tMoMg43X9gDQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch.utils.tensorboard import SummaryWriter\n","import os\n","\n","\n","writer = SummaryWriter()\n","\n","# Define the path to save checkpoints\n","save_path_way = 'model2'\n","\n","# Ensure the directory exists\n","os.makedirs(save_path_way, exist_ok=True)\n","\n","def train(model, loader, loss_function, optimizer, num_epochs=50, save_path=save_path_way):\n","    model.train()\n","\n","    total_step = len(loader)\n","    for epoch in range(num_epochs):\n","        total_loss = 0.0\n","        # stochastic gradient descent\n","        for i, (coordinate, label) in enumerate(loader):\n","            output = model(coordinate)\n","\n","            loss = loss_function(output, label)\n","\n","            optimizer.zero_grad() #Reset Gradients\n","            loss.backward() #Calculate backpropagation gradients\n","\n","            optimizer.step() #Perform parameter update step\n","\n","            total_loss += loss.item()\n","\n","            if (i+1) % 100 == 0:\n","                print('Epoch {}/{}, Step {}/{}, Loss: {:.4f}'\n","                      .format(epoch+1, num_epochs, i+1, total_step, loss.item()))\n","\n","        checkpoint = {\n","            'model': model.state_dict(),\n","            'loss': loss\n","        }\n","        torch.save(checkpoint, save_path + '/epoch_' + str(epoch+1) + '.pt')"],"metadata":{"id":"cw2OdqS59D2i"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from torch import optim\n","loss_func = torch.nn.CrossEntropyLoss()\n","optimizer = optim.Adam(instantiated_model.parameters(), lr=1e-3)\n","\n","train(instantiated_model, train_loader, loss_func, optimizer)"],"metadata":{"id":"sDpHpPkRECfl","executionInfo":{"status":"ok","timestamp":1731989209434,"user_tz":300,"elapsed":1633,"user":{"displayName":"Esequiel Linares","userId":"03329919127518825833"}}},"execution_count":53,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[],"authorship_tag":"ABX9TyOsazOZeN7zNMAN7yVCjjzv"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}